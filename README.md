没有 SLAM，虚拟现实将永远停留在座椅上。

# 第2讲　初识SLAM

1. 我在什么地方？——定位。
2. 周围环境是什么样？——建图。

当谈论视觉 SLAM 时，我们主要是指如何用相机解决定位和建图问题。

## 单目相机

近处的物体移动快，远处的物体则运动缓慢。于是，当相机移动时，这些物体在图像上的运动就形成了视差。通过视差，我们就能定量地判断哪些物体离得远，哪些物体离得近。

如果把相机的运动和场景大小同时放大两倍，单目相机所看到的像是一样的。同样地，把这个大小乘以任意倍数，我们都将看到一样的景象。这说明，单目SLAM估计的轨迹和地图将与真实的轨迹和地图相差一个因子，也就是所谓的尺度（Scale）。由于单目SLAM无法仅凭图像确定这个真实尺度，所以又称为尺度不确定性。

平移之后才能计算深度，以及无法确定真实尺度，这两件事情给单目SLAM的应用造成了很大的麻烦。其根本原因是通过单张图像无法确定深度。所以，为了得到这个深度，人们开始使用双目和深度相机。

## 双目相机和深度相机

### 双目相机

双目相机由两个单目相机组成，但这两个相机之间的距离〔称为基线（Baseline）〕是已知的。我们通过这个基线来估计每个像素的空间位置——这和人眼非常相似。我们人类可以通过左右眼图像的差异判断物体的远近，在计算机上也是同样的道理。

双目相机测量到的深度范围与基线相关。基线距离越大，能够测量到的就越远。

双目或多目相机的缺点是配置与标定均较为复杂，其深度量程和精度受双目的基线与分辨率限制，而且视差的计算非常消耗计算资源，需要使用 GPU 和 FPGA 设备加速后，才能实时输出整张图像的距离信息。因此在现有的条件下，计算量是双目的主要问题之一。

### 深度相机

深度相机（RGB-D 相机）通过主动向物体发射光并接收返回的光，测出物体离相机的距离。这部分并不像双目那样通过软件计算来解决，而是通过物理的测量手段，所以相比于双目可节省大量的计算量。

不过，现在多数 RGB-D 相机还存在测量范围窄、噪声大、视野小、易受日光干扰、无法测量透射材质等诸多问题，在 SLAM 方面，主要用于室内 SLAM，室外则较难应用。

## 经典视觉 SLAM 框架

1. 传感器信息读取
2. 视觉里程计(Visual Odometry, VO)
	- 视觉里程计关心相邻图像之间的相机运动，最简单的情况当然是两张图像之间的运动关系。
	- 仅通过视觉里程计来估计轨迹，将不可避免地出现累计漂移(Accumulating Drift)。
	- 还需要两种技术:后端优化x和回环检测。回环检测负责把“机器人回到原始位置”的事情检测出来，而后端优化则根据该信息，校正整个轨迹的形状。
3. 后端优化(Optimization)
	- 在视觉 SLAM 中，前端和计算机视觉研究领域更为相关，比如图像的特征提取与匹配等，后端则主要是滤波与非线性优化算法。
4. 回环检测(Loop Closing)
	- 又称闭环检测(Loop Closure Detection)，主要解决位置估计随时间漂移的问题。
	- 我们可以判断图像间的相似性，来完成回环检测。如果回环检测成功，可以显著地减小累积误差。
5. 建图(Mapping)
	- 度量地图(Metric Map)
		- 度量地图强调精确地表示地图中物体的位置关系。
	- 拓扑地图(Topological Map)
		- 拓扑地图更强调地图元素之间的关系。拓扑地图是一个图(Graph)，由节点和边组成，只考虑节点间的连通性，例如 A，B 点是连通的，而不考虑如何从 A 点到达 B 点的过程。

如果把工作环境限定在静态、刚体，光照变化不明显、没有人为干扰的场景，那么，这个 SLAM 系统是相当成熟的了。

## SLAM 问题的数学表述

- 运动方程：x_k = f (x_{k−1},u_k,w_k)
- 观测方程：z_{k,j} = h (y_j,x_k,v_{k,j})

> 我们按照运动和观测方程是否为线性，噪声是否服从高斯分布进行分类，分为线性/非线性和高斯/非高斯系统。其中线性高斯系统(Linear Gaussian, LG 系统)是最简单的，它的无偏的最优估计可以由卡尔曼滤波器(Kalman Filter, KF)给出。而在复杂的非线性非高斯系统(Non-Linear Non-Gaussian，NLNG 系统)中，我们会使用以扩展卡尔曼滤波器(Extended Kalman Filter, EKF)和非线性优化两大类方法去求解它。




















